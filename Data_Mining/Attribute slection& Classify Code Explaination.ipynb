{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. ClassifierAttributeEval\n",
    "X1=dm[['opusNum','followerNumInc','type','followerNum','name','likeNum','commentNum','uid']]\n",
    "\n",
    "#2. CfsSubsetEval\n",
    "X2=dm[['opusNum','originalMusicBeUsedNum']]\n",
    "    \n",
    "\n",
    "#3. CorrelationAttributeEval\n",
    "X3=dm[['likeNum','commentNum','likeNum','douyinFansNum','fansTotal','followerNum','repostNum',\n",
    "    'toutiaoFansNum','originalMusicBeUsedNum','originalMusicNum','type']]\n",
    "\n",
    "#4. ReliefFAttributeEval \n",
    "X4=dm[['name','likeNum','commentNum','originalMusicBeUsedNum','toutiaoFansNum','repostNum','originalMusicNum',\n",
    "      'followerNumInc','huoshanFansNum']]\n",
    "\n",
    "\n",
    "#Chosen by myself\n",
    "X5=dm[['commentNum','followerNum','followerNumInc','type','repostNum','likeNum','opusNum',\n",
    "      'likeOpusNum','fansTotal','douyinFansNum','dynamicNum']]\n",
    "\n",
    "Y=dm[['rankPosition']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data to get the training set(70%) and test set(30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X,Y,selection):\n",
    "    global X_train,X_test,Y_train,Y_test,x_vaild,y_vaild,X_test,Y_test\n",
    "    le=LabelEncoder()\n",
    "    z=StandardScaler().fit_transform(X)\n",
    "    Y=le.fit_transform(Y)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(z,Y,test_size=0.3,random_state=9)\n",
    "    x_vaild=X_test[-20:,:]\n",
    "    y_vaild=Y_test[-20:]\n",
    "    X_test=X_test[:-20,:]\n",
    "    Y_test=Y_test[:-20]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN (k-nearest neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_rate():\n",
    "    global error_rate    \n",
    "    error_rate=[]\n",
    "    for k in range(1,31,2):\n",
    "        knn_classifier= KNeighborsClassifier(n_neighbors=k)\n",
    "        knn_classifier.fit(X_train,Y_train)\n",
    "        pred_k=knn_classifier.predict(X_test)\n",
    "        error_rate.append(np.mean(pred_k!=Y_test))\n",
    "    #y_test=np.array(np.random.randint(0,2,(52,)))\n",
    "    #y_test=y_test.astype(float)\n",
    "    \n",
    "    plt.figure(figsize=(10,4))\n",
    "    ax=plt.gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.plot(range(1,31,2),error_rate,color='red',linestyle='dashed',\n",
    "             marker='o',markerfacecolor='black',markersize=10)\n",
    "    plt.title('Error rate vs. k for Tik Tok Subset')\n",
    "    plt.xlabel('number of neighbors: k')\n",
    "    plt.ylabel('Error Rate')\n",
    "    return\n",
    "\n",
    "\n",
    "def KNN(x_vaild,y_vaild,k):\n",
    "    knn_classifier= KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_classifier.fit(X_train,Y_train)\n",
    "    y_score=knn_classifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "    new_instance=x_vaild\n",
    "    prediction=knn_classifier.predict(new_instance.reshape(len(y_vaild),-1))\n",
    "\n",
    "    #print('KNN Prediction: ',prediction)\n",
    "    #print('KNN Vaild: ', y_vaild)\n",
    "    print('KNN Correct', np.mean(prediction==y_vaild))\n",
    "    #c_m=confusion_matrix(Y_test,prediction)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(Y_test, y_score)\n",
    "    print('TP rate: '+ str(np.mean(tpr_rf).tolist()))\n",
    "    print('FP rate: '+ str(np.mean(fpr_rf).tolist()))\n",
    "    print('ROC Area: '+str(roc_auc_score(Y_test, y_score).tolist()))\n",
    "    print('\\n') \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayesian(x_vaild,y_vaild):\n",
    "    NB_classifier = GaussianNB().fit(X_train, Y_train)\n",
    "    y_score=NB_classifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "    new_instance = x_vaild\n",
    "    prediction = NB_classifier.predict(new_instance)\n",
    "    \n",
    "   # print('NB Prediction: ',prediction)\n",
    "   # print('NB Vaild: ', y_vaild)\n",
    "    print('NB Correct', np.mean(prediction==y_vaild))\n",
    "    #c_m=confusion_matrix(Y_test,prediction)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(Y_test, y_score)\n",
    "    print('TP rate: '+ str(np.mean(tpr_rf).tolist()))\n",
    "    print('FP rate: '+ str(np.mean(fpr_rf).tolist()))\n",
    "    print('ROC Area: '+str(roc_auc_score(Y_test, y_score).tolist()))\n",
    "    print('\\n')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SVC (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_classify(X_test,Y_test):\n",
    "    clf=SVC(gamma='auto')\n",
    "    clf.fit(X_train,Y_train)\n",
    "    y_score=clf.fit(X_train,Y_train).decision_function(X_test)\n",
    "\n",
    "    prediction=clf.predict(X_test.reshape(len(Y_test),-1)) \n",
    "    correct=np.mean(prediction==Y_test)       \n",
    "    #print('SVC Prediction: ',prediction)\n",
    "    #print('SVC Vaild: ', Y_test)\n",
    "    print('SVC Correct', correct)    \n",
    "    #c_m=confusion_matrix(Y_test,prediction)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(Y_test, y_score)\n",
    "    print('TP rate: '+ str(np.mean(tpr_rf).tolist()))\n",
    "    print('FP rate: '+ str(np.mean(fpr_rf).tolist()))\n",
    "    print('ROC Area: '+str(roc_auc_score(Y_test, y_score).tolist()))\n",
    "    print('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MLP (multilayer perceptron)\n",
    "## A feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_classifier(X_test,Y_test):\n",
    "    mlp=MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, alpha=1e-4,\n",
    "                        solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                        learning_rate_init=.1)\n",
    "    #mlp.fit(X_train,Y_train)\n",
    "    y_score=mlp.fit(X_train,Y_train).predict_proba(X_test)[:,1]\n",
    "    prediction=mlp.predict(X_test.reshape(len(Y_test),-1)) \n",
    "    correct=np.mean(prediction==Y_test)   \n",
    "    print('\\nMLP Correct', correct) \n",
    "    #c_m=confusion_matrix(Y_test,prediction)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(Y_test, y_score)\n",
    "    print('TP rate: '+ str(np.mean(tpr_rf).tolist()))\n",
    "    print('FP rate: '+ str(np.mean(fpr_rf).tolist()))\n",
    "    print('ROC Area: '+str(roc_auc_score(Y_test, y_score).tolist()))\n",
    "    print('\\n')   \n",
    "    \n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the four different classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={'Attribute Selection':X1,'CfsSubsetEval':X2,'CorrelationAttributeEval':X3,\n",
    "       'ReliefFAttributeEval':X4,'Chosen by myself':X5}\n",
    "for selection,i in dict1.items(): \n",
    "    print(selection)\n",
    "    preprocess(i,Y,selection)\n",
    "    er_rate()\n",
    "    num=error_rate.index(min(error_rate))\n",
    "    k=2*num+1\n",
    "    KNN(X_test,Y_test,k) \n",
    "    Naive_Bayesian(X_test,Y_test)\n",
    "    SVC_classify(X_test,Y_test)\n",
    "    mlp_classifier(X_test,Y_test)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
